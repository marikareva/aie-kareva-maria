# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`

- Размер: (Строки: 12000, Столбцы: 30)

- Целевая переменная: `target` (Тип: бинарная классификация (0 или 1); распределение: 

Class 0: 8119 (67.7%) - мажоритарный класс , Class 1: 3881 (32.3%) - миноритарный класс; Соотношение: 2.09:1

(умеренный дисбаланс). Всего: 12,000 наблюдений)

- Признаки: 

Числовые признаки (24 шт): `num01 - num24`: 24 числовых признака, тип: `float64` (вещественные числа)

Примеры: `num01, num02, ..., num24`

Категориальные признаки (3 шт): `cat_contract:` тип контракта (целые числа), `cat_region:` регион (целые числа),

`cat_payment:` метод оплаты (целые числа), тип: `int64`, но по смыслу категориальные

Временной признак (1 шт): `tenure_months:` срок пользования в месяцах, тип: `int64`

## 2. Protocol

- Разбиение: train/test 

Доли: 75% train / 25% test

Random state: random_state=42 (для воспроизводимости результатов)

Размеры выборок:

- Исходный датасет: 12,000 наблюдений

    Class 0: 8,119 (67.7%)

    Class 1: 3,881 (32.3%)

- Train set: 9,000 наблюдений (75%)

    Class 0: 6,089 (67.7%)

    Class 1: 2,911 (32.3%)

- Test set: 3,000 наблюдений (25%)

    Class 0: 2,030 (67.7%)

    Class 1: 970 (32.3%)

- Подбор: CV на train (сколько фолдов, что оптимизировали)

    Для `RandomForest`:

         Оптимизировали: F1-score

         Лучший F1 (CV): 0.8819

         Использованные параметры для GridSearch:

         n_estimators: 50, 100, 200

         max_depth: None, 5, 10

         max_features: 'sqrt', 'log2'

         Лучшие параметры: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}

     Для `GradientBoosting`:

        Оптимизировали: F1-score

        Лучший F1 (CV): 0.8835

        Использованные параметры:

        n_estimators: 50, 100, 200

        max_depth: 3, 5, 7

        learning_rate: 0.01, 0.1, 0.3

        Лучшие параметры: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}

    Использовалось: 5 фолдов (стратифицированных)

- Метрики: accuracy, F1, ROC-AUC (и почему эти метрики уместны именно здесь)
    
    Метрики качества:

        Accuracy и F1-score (бинарная классификация):

        Модель                    Accuracy   F1-score 

        DummyClassifier           0.6767     0.0000 

        LogisticRegression        0.8297     0.7147

        DecisionTree (simple)     0.8567     0.7767

        DecisionTree (controlled) 0.8443     0.7271

        RandomForest              0.9307     0.8878 

        GradientBoosting          0.9257     0.8802    


        ROC-AUC (только модели с вероятностями):

        Модель                    ROC-AUC

        LogisticRegression        0.8789

        DecisionTree (simple)     0.8343 

        DecisionTree (controlled) 0.8624 

        RandomForest              0.9697  

        GradientBoosting          0.9686  

        DummyClassifier           N/A 

    Три выбранные метрики образуют полную картину:

    Accuracy - общий индикатор, легко интерпретировать

    F1-Score - балансирует бизнес-критические precision/recall, учитывает дисбаланс

    ROC-AUC - оценивает фундаментальную силу модели, позволяет калибровать порог

    Для этой конкретной задачи с дисбалансом классов F1-Score является наиболее важной метрикой, что подтверждается 
    
    ее использованием как оптимизируемой метрики в кросс-валидации и отличными результатами лучшей модели (0.8878).

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier (baseline)

    Стратегия: 'most_frequent' (всегда предсказывает самый частый класс)

    Accuracy:  0.6767

    Precision: 0.0000

    Recall:    0.0000

    F1-score:  0.0000

- LogisticRegression (baseline из S05)

    Accuracy:  0.8297

    Precision: 0.7795

    Recall:    0.6598

    F1-score:  0.7147

- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf` или `ccp_alpha`)

    Без ограничений:

    Accuracy (train): 1.0000

    Accuracy (test):  0.8567

    С контролем сложности (max_depth=5, min_samples_leaf=5):

    Accuracy (train): 0.8638

    Accuracy (test):  0.8443

- RandomForestClassifier

    Лучшие параметры: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}

    F1 (CV): 0.8819

    Accuracy (test): 0.9307

    F1 (test): 0.8878

- Один boosting (AdaBoost / GradientBoosting / HistGradientBoosting)

    GradientBoosting:

    Лучшие параметры: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}

    F1 (CV): 0.8835

    Accuracy (test): 0.9257

    F1 (test): 0.8802

## 4. Results

- Таблица/список финальных метрик на test по всем моделям

    1. Accuracy и F1-score (бинарная классификация):

    Модель                    Accuracy   F1-score 

    DummyClassifier           0.6767     0.0000 

    LogisticRegression        0.8297     0.7147

    DecisionTree (simple)     0.8567     0.7767

    DecisionTree (controlled) 0.8443     0.7271

    RandomForest              0.9307     0.8878 

    GradientBoosting          0.9257     0.8802  

    2. ROC-AUC (только модели с вероятностями):

    Модель                    ROC-AUC   

    LogisticRegression        0.8789 

    DecisionTree (simple)     0.8343  

    DecisionTree (controlled) 0.8624 

    RandomForest              0.9697 

    GradientBoosting          0.9686 

    DummyClassifier           N/A 

- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение
    
    Победитель: RandomForestClassifier

    Краткое объяснение выбора:

    По основному критерию (F1-Score): RandomForest показывает наивысший результат (0.8878), что означает 
    
    оптимальный баланс между точностью обнаружения уходящих клиентов и минимизацией ложных тревог.

    По всем остальным метрикам: RandomForest также лидирует или находится на первом месте. Также демонстрирует
    
    минимальный разрыв между train и test производительностью, что свидетельствует о хорошей обобщающей способности.

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко

    Проведено 5 независимых прогонов для двух ключевых моделей с разными значениями random_state:

        RandomForest (победитель)

        GradientBoosting (ближайший конкурент)

    Статистика по 5 прогонам RandomForest:

        Среднее Accuracy: 0.9297 ± 0.0010 (0.11% стандартное отклонение)

        Среднее F1-Score: 0.8870 ± 0.0012 (0.14% стандартное отклонение)

        Среднее ROC-AUC: 0.9695 ± 0.0005 (0.05% стандартное отклонение)

    Статистика по 5 прогонам GradientBoosting:

        Среднее Accuracy: 0.9249 ± 0.0012 (0.13% стандартное отклонение)

        Среднее F1-Score: 0.8793 ± 0.0014 (0.16% стандартное отклонение)

        Среднее ROC-AUC: 0.9683 ± 0.0007 (0.07% стандартное отклонение)

- Ошибки: confusion matrix для лучшей модели + комментарий

    |              | Predicted 0 | Predicted 1 | Total |
    |--------------|-------------|-------------|-------|
    | **Actual 0** | 1969        | 61          | 2030  |
    | **Actual 1** | 147         | 823         | 970   |
    | **Total**    | 2116        | 884         | 3000  |

    Статистика(комментарий) по классам:

        Класс 0 (Не уходят) - 2030 наблюдений:

        TN (True Negative): 1969

        FP (False Positive): 61

        Точность класса 0: 1969/2030 = 97.00% (высокая!)

        Ошибки класса 0: 61/2030 = 3.00%

        Класс 1 (Уходят) - 970 наблюдений:

        TP (True Positive): 823

        FN (False Negative): 147

        Точность класса 1: 823/970 = 84.85% (хорошая)

        Ошибки класса 1: 147/970 = 15.15%

- Интерпретация: permutation importance (top-10/15) + выводы

    PERMUTATION IMPORTANCE (top-10 признаков)

    Признак  Важность

    num19  0.092433

    num18  0.075300

    num07  0.041467

    num04  0.021200

    num24  0.015300

    num20  0.010967

    num22  0.008200

    num01  0.007700

    num21  0.007533

    num17  0.007367

    Выводы: Анализ матрицы ошибок подтвердил оптимальный баланс между различными типами классификационных ошибок. 
    
    Модель демонстрирует высокую устойчивость к изменениям начальных условий (random_state), что обеспечивает 
    
    воспроизводимость результатов в производственной среде. Результаты анализа важности признаков методом 
    
    permutation importance выявили ключевые факторы, влияющие на
    
    прогнозирование оттока клиентов. Числовые признаки, в особенности num19, num18 и num07, обладают наибольшей 
    
    предсказательной силой. Данное обстоятельство позволяет как оптимизировать саму модель, так и совершенствовать 
    
    бизнес-процессы, фокусируя усилия на мониторинге и управлении наиболее значимыми показателями.

    Текущая конфигурация модели RandomForestClassifier, с подобранными гиперпараметрами и порогом классификации 0,
    
    5, признана оптимальной для развертывания в производственной среде.

## 6. Conclusion

- Ключевые выводы о деревьях и ансамблевых методах:

    Одиночные деревья решений склонны к переобучению - DecisionTree без ограничений показал train accuracy 100% при
    
    test accuracy 85.67%, что демонстрирует критическую важность регуляризации через max_depth и min_samples_leaf.

    Ансамблевые методы существенно превосходят одиночные модели - RandomForest улучшил F1-score на 14.5%
    
    относительно LogisticRegression и на 11.1% относительно регуляризованного DecisionTree, подтверждая 
    
    эффективность bagging-подхода.
    
    Разные типы ансамблей дают сравнимые результаты - RandomForest (F1=0.8878) и GradientBoosting (F1=0.8802) 
    
    показали близкую производительность, что указывает на устойчивость ансамблевых подходов в целом.

- Ключевые выводы о честном ML-протоколе:
    
    Стратифицированное разделение критически важно при дисбалансе - сохранение распределения 67.7%/32.3% в train/
    
    test выборках обеспечило репрезентативную оценку производительности модели на миноритарном классе.

    Оптимизация по F1-score адекватнее accuracy при дисбалансе классов - использование F1 как основной метрики для 
    
    кросс-валидации предотвратило оптимизацию модели в ущерб миноритарному классу.

    Hold-out test set обязателен для финальной оценки - разделение данных до любого анализа и использование test 
    
    set только для финальной оценки предотвратило data leakage и обеспечило честную оценку обобщающей способности 
    
    моделей.


