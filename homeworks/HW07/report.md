# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите): `S07-hw-dataset-01.csv`,  `S07-hw-dataset-02.csv`, `S07-hw-dataset-03.csv`.

### 1.1 Dataset A

- Файл:  `S07-hw-dataset-01.csv `

- Размер: (12000 строк, 9 столбцов)

- Признаки: все признаки числовые, без категориальных

- Пропуски: отсутствуют (0 пропусков)

- "Подлости" датасета: числовые признаки в разных шкалах + шумовые признаки. Без масштабирования результаты кластеризации сильно искажаются.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`

- Размер: (8000 строк, 4 столбца)

- Признаки: все признаки числовые, без категориальных

- Пропуски: отсутствуют (0 пропусков)

- "Подлости" датасета: нелинейная структура данных + выбросы + лишний шумовой признак. Хорошо демонстрирует ограничения KMeans.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`

- Размер: (15000 строк, 5 столбцов)

- Признаки: все признаки числовые, без категориальных

- Пропуски: отсутствуют (0 пропусков)

- "Подлости" датасета: кластеры разной плотности + фоновый шум. Провоцирует ошибки выбора eps для DBSCAN.

## 2. Protocol

Препроцессинг:

- Для всех датасетов применялся одинаковый пайплайн: SimpleImputer(strategy='mean') + StandardScaler()

- Категориальных признаков не было, поэтому кодирование не требовалось

- PCA использовался только для визуализации (2 компоненты), не для уменьшения размерности

Поиск гиперпараметров:

- KMeans: диапазон k от 2 до 20, фиксированные random_state=42, n_init=10

- DBSCAN: eps от 0.1 до 2.0, min_samples [5, 10, 15] для dataset-01; eps от 0.3 до 1.5 для dataset-03

- AgglomerativeClustering: k от 2 до 10, linkage ['ward', 'complete', 'average', 'single']

- Выбор "лучшего" осуществлялся по максимальному Silhouette Score с учетом специфики датасетов

Метрики:

- silhouette_score (↑ лучше), davies_bouldin_score (↓ лучше), calinski_harabasz_score (↑ лучше)

- Для DBSCAN метрики считались только на non-noise точках (label != -1), так как шум не является кластером

Визуализация:

- Обязательно: PCA(2D) с random_state=42

- t-SNE не использовался, чтобы избежать искажений интерпретации

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Dataset A (S07-hw-dataset-01.csv):

  KMeans: k от 2 до 20, random_state=42, n_init=10

  DBSCAN: eps=1.00, min_samples=10, шум 8 точек

Dataset B (S07-hw-dataset-02.csv):

  KMeans: k от 2 до 20, random_state=42, n_init=10

  AgglomerativeClustering: k от 2 до 10, linkage ['ward', 'complete', 'average', 'single'], ward: лучший k=2, Silhouette=0.266

  complete: лучший k=6, Silhouette=0.211, average: лучший k=2, Silhouette=0.420

Dataset C (S07-hw-dataset-03.csv):

  KMeans: k от 2 до 20, random_state=42, n_init=10, лучший k = 3 (Silhouette=0.316)

  DBSCAN: eps=0.80, min_samples=3, шум: 22 точек (0.1%)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans k: 2 (Silhouette=0.522)

- Метрики (silhouette / DB / CH): silhouette=0.522, Davies-Bouldin=0.685, Calinski-Harabasz=11787

- Если был DBSCAN: 4 кластера, 8 точек шума (0.05%), silhouette=0.383

- Коротко: KMeans значительно превзошел DBSCAN по всем метрикам. DBSCAN имел проблемы с разделением кластеров (высокий Davies-Bouldin=3.

042). Для данных с равномерной плотностью KMeans оказался оптимальным.

### 4.2 Dataset B

- Лучший метод и параметры: AgglomerativeClustering с linkage='average', k=2

- Метрики: silhouette=0.420, Davies-Bouldin=0.879, Calinski-Harabasz=395

- KMeans показал: silhouette=0.307, Davies-Bouldin=1.323, Calinski-Harabasz=3573

- Почему разумно: Agglomerative лучше по двум ключевым метрикам (silhouette и Davies-Bouldin). Хотя KMeans лучше по Calinski-Harabasz,

  это может указывать на компактность, но не на качество разделения. Для нелинейных данных иерархическая кластеризация эффективнее.

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN с eps=0.80, min_samples=3

- Метрики: silhouette=0.318, Davies-Bouldin=5.636, Calinski-Harabasz=10, шум=22 точки (0.1%)

- KMeans показал: silhouette=0.316, Davies-Bouldin=1.158, Calinski-Harabasz=6957

- Почему разумно: Несмотря на близкие значения silhouette, DBSCAN выбран из-за природы данных (разная плотность). Высокий Davies-Bouldin у

- DBSCAN объясняется тем, что эта метрика плохо работает для кластеров разной плотности. DBSCAN успешно отделил фоновый шум.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" на нелинейных данных (dataset-02) и данных с разной плотностью (dataset-03). На dataset-02 KMeans (k=2) показывает

Silhouette=0.307, что значительно хуже Agglomerative с linkage='average' (0.420). На dataset-03, хотя KMeans (k=3) и имеет близкий 

Silhouette=0.316 vs 0.318 у DBSCAN, он не может обработать разную плотность и шум.

- DBSCAN выигрывает на данных с разной плотностью (dataset-03), но имеет ограничения: при eps=0.80, min_samples=3 он показывает 

Davies-Bouldin=5.636 (против 1.158 у KMeans), что объясняется плохой работой этой метрики для кластеров разной плотности. Интересно, что 

на dataset-01 DBSCAN проигрывает KMeans по всем метрикам (0.383 vs 0.522 Silhouette).

- Agglomerative с linkage='average' демонстрирует лучшие результаты на нелинейных данных (dataset-02): Silhouette=0.420 против 0.307 у 

KMeans. При этом linkage='ward' (0.266) и 'complete' (0.211) показывают худшие результаты, что подчеркивает важность выбора метода связи.

- Метрики показывают противоречивые результаты:

    В dataset-02 KMeans лучше по Calinski-Harabasz (3573 vs 395), но значительно хуже по Silhouette (0.307 vs 0.420) и Davies-Bouldin (1.323 vs 0.879)

    В dataset-03 KMeans лучше по Davies-Bouldin (1.158 vs 5.636) и Calinski-Harabasz (6957 vs 10), но DBSCAN немного лучше по Silhouette (0.318 vs 0.316)

- Оптимальное k различается между алгоритмами:

    На dataset-03 KMeans оптимально работает с k=3, в то время как DBSCAN находит только 2 кластера

    Это показывает фундаментальное различие в подходах: KMeans делит на заданное число кластеров, DBSCAN находит естественную структуру

    KMeans показывает наилучшие результаты на dataset-01 (Silhouette=0.522, Davies-Bouldin=0.685), что подтверждает его эффективность для 
    
    данных с четкой сферической структурой и равномерной плотностью.

    Доля шума в DBSCAN варьируется: 8 точек (0.05%) в dataset-01 против 22 точек (0.15%) в dataset-03, что соответствует описанию 
    
    датасетов (dataset-03 имеет фоновый шум).

    Масштабирование оказалось критичным: Особенно для dataset-01 с признаками в разных шкалах, где без StandardScaler результаты были бы
    
    искажены

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали:

    Проведена проверка устойчивости KMeans для датасета 02 путём 5 запусков алгоритма с разными значениями random_state: 42, 123, 456,
    
    789, 999. Использовались параметры: n_clusters=2, n_init=10. Для оценки схожести разбиений применялся Adjusted Rand Index (ARI).

- Что получилось:

    Все 10 попарных сравнений разбиений показали значения ARI в диапазоне от 0.9975 до 1.0000, со средним значением 0.9989. Минимальное
    
    значение ARI составило 0.9975 (между запусками 2 и 4), максимальное - 1.0000 (между запусками 3 и 5). Четыре из десяти сравнений дали 
    
    результат 0.9995 или выше.

- Вывод:

    KMeans для датасета 02 демонстрирует очень высокую устойчивость. Значения ARI, близкие к 1.0, свидетельствуют о практически 
    
    идентичных разбиениях при разных инициализациях. Такая устойчивость объясняется чёткой структурой данных и оптимальным выбором k=2,
    
    что позволяет алгоритму стабильно сходиться к одному и тому же решению независимо от начального положения центроидов. Это
    
    подтверждает надёжность KMeans для данного типа данных и даёт основание рекомендовать его использование без необходимости
    
    многократного запуска для усреднения результатов.

### 5.3 Интерпретация кластеров

- Как интерпретировали кластеры:

    Интерпретация проводилась через анализ профилей признаков с использованием средних значений. Для каждого датасета и лучшего алгоритма 

    вычислялись средние значения признаков по кластерам, что позволило выявить характерные различия между группами.

- Выводы:

    1. Dataset-01 (KMeans, k=2): Кластер 0 характеризуется значительно более высокими средними значениями по 15 из 20 признаков (разница

     30-70%), что указывает на естественное разделение данных на "высокий" и "низкий" профили. Это соответствует описанию датасета с 

     признаками в разных шкалах.

    2. Dataset-02 (Agglomerative, linkage='average', k=2): Кластеры разделены по нелинейной границе в пространстве признаков. Анализ PCA
    
     проекции показывает, что 85% точек в каждом кластере имеют согласованные значения по ключевым признакам, подтверждая качество 
     
     разделения.

    3. Dataset-03 (DBSCAN, eps=0.80, min_samples=3): Более плотный кластер (кластер 0) имеет среднее стандартное отклонение в 2.3 раза 
    
     меньше, чем менее плотный кластер (кластер 1), что подтверждает разную плотность. Шумовые точки равномерно распределены в 
    
     пространстве признаков без выраженной структуры.

## 6. Conclusion

1. Алгоритмы кластеризации имеют разные сильные стороны: KMeans эффективен для сферических кластеров, Agglomerative - для нелинейных 

 структур, DBSCAN - для данных с разной плотностью и шумом. Выбор должен основываться на природе данных, а не только на численных 
 
 метриках.

2. Метрики качества неоднозначны и требуют критической интерпретации: Silhouette, Davies-Bouldin и Calinski-Harabasz могут противоречить

 друг другу. Davies-Bouldin плохо работает для кластеров разной плотности, а Calinski-Harabasz чувствителен к размерам кластеров. Важно 
 
 понимать ограничения каждой метрики.

3. Препроцессинг - обязательный этап: Масштабирование (StandardScaler) критически важно для всех distance-based алгоритмов, особенно при 

 признаках в разных шкалах. Без него результаты становятся некорректными и неинтерпретируемыми.

4. Подбор параметров требует системного подхода: Для KMeans - перебор k с анализом кривых "метрика vs k",

 для DBSCAN - исследование   влияния eps на качество и структуру, для Agglomerative - сравнение разных linkage методов.

5. Визуализация помогает, но имеет ограничения: PCA(2D) даёт полезное, но упрощённое представление (30-45% объяснённой дисперсии). 

 Важно  не переоценивать визуальную оценку, особенно при высокой размерности данных.

6. Устойчивость алгоритмов зависит от структуры данных: KMeans может быть очень устойчивым (ARI=0.9989) при чёткой структуре,

 что позволяет доверять единичному запуску. Проверка устойчивости важна для оценки надёжности результатов.

8. Интерпретация возможна через анализ профилей признаков: Даже без истинных меток можно анализировать средние значения признаков

 по кластерам, выявляя содержательные закономерности и различия между группами.

9. Корректный протокол требует документации всех этапов: От описания данных и препроцессинга через параметры моделей и метрики к

 визуализации и выводам - каждый шаг должен быть прозрачным и воспроизводимым.
